{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gaaKhoRmCIRR","executionInfo":{"status":"ok","timestamp":1732843588218,"user_tz":300,"elapsed":1418,"user":{"displayName":"Owen Van Esbroeck","userId":"13137652672025469070"}},"outputId":"f83c2aaa-3a12-4a94-f6d0-cef6ce1854e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"mVyl0bLBaQyE"},"source":["#### Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JYexFoOvwRfK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732843608793,"user_tz":300,"elapsed":20577,"user":{"displayName":"Owen Van Esbroeck","userId":"13137652672025469070"}},"outputId":"68778337-ab0a-496b-9b65-8c6346cb04c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["!pip install transformers\n","\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import logging\n","import nltk\n","import json\n","import regex\n","import math\n","import torch\n","import random\n","\n","\n","from nltk.corpus import stopwords\n","from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n","from transformers.models.bert.tokenization_bert import BasicTokenizer\n","from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertForSequenceClassification\n","\n","nltk.download('stopwords')\n","\n","\n","\n","def load_file(path):\n","  file = open(path)\n","  lines = file.readlines()\n","  json_arr = [json.loads(x) for x in lines]\n","  return json_arr\n"]},{"cell_type":"code","source":["OUTPUT_DIR = \"/tmp/\"\n","BASE_DIR = \"drive/MyDrive/GenAIContentDetection/\"\n","\n","english = {\n","  \"bert_model\": \"bert-base-cased\",\n","  \"path\": BASE_DIR + \"Datasets/English/academic_essay_english_train.jsonl\",\n","  \"test_path\": BASE_DIR + \"Datasets/English/academic_essay_english_dev.jsonl\",\n","  \"unlabeled\": BASE_DIR + \"Datasets/English/academic_essay_english_dev_test_no_label.jsonl\"\n","}\n","\n","arabic = {\n","  \"bert_model\": \"bert-base-multilingual-cased\",\n","  \"path\": BASE_DIR + \"Datasets/Arabic/academic_essay_arabic_train.jsonl\",\n","  \"test_path\": BASE_DIR + \"Datasets/Arabic/academic_essay_arabic_dev.jsonl\",\n","  \"unlabeled\": BASE_DIR + \"Datasets/Arabic/academic_essay_arabic_dev_test_no_label.jsonl\"\n","}\n","\n","daigt = {\n","  \"bert_model\": \"bert-base-cased\",\n","  \"path\": BASE_DIR + \"Datasets/DAIGT/daigt_essay_train.jsonl\",\n","  \"test_path\": BASE_DIR + \"Datasets/DAIGT/daigt_essay_dev.jsonl\",\n","}\n","\n","datasets = {\n","    \"english\": english,\n","    \"arabic\": arabic,\n","    \"daigt\": daigt\n","}"],"metadata":{"id":"YNVY_E1X3VUh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Additional data"],"metadata":{"id":"SJmuF9U-29UY"}},{"cell_type":"code","source":["import json\n","\n","def average_essay_length(json_files):\n","    total_word_count = 0\n","    essay_count = 0\n","\n","    for file_path in json_files:\n","        with open(file_path, 'r') as f:\n","            for line in f:\n","                data = json.loads(line)\n","                essay = data.get(\"essay\", \"\")  # Get the \"essay\" value, or \"\" if not found\n","                words = essay.split()\n","                total_word_count += len(words)\n","                essay_count += 1\n","\n","    if essay_count == 0:\n","        return 0  # Avoid division by zero if no essays are found\n","\n","    average_length = total_word_count / essay_count\n","    return average_length\n","\n","file_paths = [datasets[\"english\"][\"path\"]]  # Replace with your file paths\n","average_length = average_essay_length(file_paths)\n","print(f\"Average essay length (in words): {average_length}\")"],"metadata":{"id":"FyTuGMe52Jq1","executionInfo":{"status":"ok","timestamp":1732843608793,"user_tz":300,"elapsed":4,"user":{"displayName":"Owen Van Esbroeck","userId":"13137652672025469070"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba221c02-9252-44f3-fdd7-4ef042f632ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average essay length (in words): 288.92891221374043\n"]}]},{"cell_type":"code","source":["def chat_llm(prompt):\n","  genai.configure(api_key=\"YOUR-KEY-HERE\")\n","\n","\n","  model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n","\n","  result = model.generate_content(prompt)\n","  return result.text.split(\"$$$$$\")\n","\n","\n","def enlarge(input_files=[], num_essays=10, essay_length=300, num_sentences=100, num_paraphrase=1):\n","    data = []\n","    for file in input_files:\n","        data.extend(load_file(file))\n","\n","    generated_essays = []\n","    selected_sentences = []\n","    while len(selected_sentences) < num_sentences:\n","        sample_essay = random.choice(data)[\"essay\"]\n","        sentences = sample_essay.split(\".\")\n","        selected_sentence = random.choice(sentences).strip()\n","        if selected_sentence and selected_sentence not in selected_sentences:\n","            selected_sentences.append(selected_sentence)\n","    print(selected_sentences)\n","    prompt = f\"\"\"\n","    # System\n","    Write {num_essays} academic essays no title is required and the essay is expected to be one continuous block of text, each approximately {essay_length} words long.\n","    Write the essays to incorporate the following sentences into the various parts of the essay, you are only allowed to use the given sentence at max {num_paraphrase} in the entire collection of resulting essay, if this is greater one ensure that the exact same sentence is not being used rather the sentence is modified while maintaining its semantic meaning:\n","    {\" \".join(selected_sentences)}\n","    Each essay should be distinct, and the sentences should be used in different combinations and contexts in each essay.\n","    The essays are to be returned as a list of string seperated by $$$$$\n","    # Response\n","    \"\"\"\n","    new_essays = chat_llm(prompt)\n","    return new_essays"],"metadata":{"id":"elsoQ4uY2LNA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SWW1WpSPY6wY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-xSNeyXvaQIu"},"source":["#### Preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-y-r6dq01Huw"},"outputs":[],"source":["#Not used\n","#def preprocess(text, language=\"english\"):\n","#  stop_words = \"|\".join(regex.sub(r\"\\'\", '', word) for word in stopwords.words(language))\n","#  text = text.lower()\n","#  text = regex.sub(r\"[?!_:\\.\\,\\-\\'\\\"\\)\\(\\/\\*@\\n0-9]\", \" \", text)\n","#  text = regex.sub(r\"\\b(\" + stop_words + r\")\\b\", \"\", text)\n","#  text = regex.sub(r\" +\", \" \", text)\n","#  return text\n","\n","def create_dataframe(input):\n","  output = []\n","  for line in input:\n","    output.append(line)\n","  return pd.DataFrame.from_dict(output)\n","\n","def create_dataframe_from_file(path, max_size=1000):\n","  lines = load_file(path)\n","  df = create_dataframe(lines)\n","  if len(lines) > max_size:\n","    df = df.sample(n=max_size)\n","  return df\n","\n","\n","def load_dfs(language, ):\n","  df = create_dataframe_from_file(datasets[language][\"path\"], max_size=10000)\n","  test_df = create_dataframe_from_file(datasets[language][\"test_path\"], max_size=5000)\n","  dev_df = test_df\n","  return df, test_df, dev_df\n","\n","#df, test_df, dev_df = load_dfs(\"daigt\")\n","#print(dev_df)"]},{"cell_type":"markdown","metadata":{"id":"hIvjIA0vacCA"},"source":["#### Naive Bayes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-WPB8homJ1u"},"outputs":[],"source":["def vocab_dictionary(df):\n","  vocab_dict={}\n","  for _, row in df.iterrows():\n","    words = filter(lambda w: w != '', row[\"essay\"].split(\" \"))\n","    for word in words:\n","      vocab_dict[word] = vocab_dict.get(word, 0) + 1\n","  return vocab_dict\n","\n","class AIDetector:\n","  def train(self, df, smoothing_factor=0.01):\n","    self.train_df = df\n","    self.train_vocab = vocab_dictionary(df)\n","    human_vocab = vocab_dictionary(df[df['label']==\"human\"])\n","    ai_vocab = vocab_dictionary(df[df['label']==\"ai\"])\n","    self.vocab_sorted = sorted(self.train_vocab.items(), key=lambda x: x[1], reverse=True)\n","    self.human_prior = len(df[df['label']==\"human\"].index) / len(df.index) #calculate positive prior\n","    self.ai_prior = len(df[df['label']==\"ai\"].index) / len(df.index) #calculate negative prior\n","    self.likelihood = {}\n","    number_instances_human = sum(human_vocab.values())\n","    number_instances_ai = sum(ai_vocab.values())\n","    number_types = len(self.train_vocab)\n","    for word, count in self.train_vocab.items():\n","      human_likelihood = (human_vocab.get(word, 0) + smoothing_factor ) / (number_instances_human + (smoothing_factor * number_types))\n","      ai_likelihood = (ai_vocab.get(word, 0) + smoothing_factor ) / (number_instances_ai + (smoothing_factor * number_types))\n","      self.likelihood[word] = {\"human\": math.log(human_likelihood), \"ai\": math.log(ai_likelihood)}\n","\n","\n","  def classify_essay(self, essay):\n","    tokens = list(filter(lambda x: x in self.likelihood, essay.split(\" \")))\n","    log_score_human = math.log(self.human_prior) + sum([self.likelihood[word][\"human\"] for word in tokens])\n","    log_score_ai = math.log(self.ai_prior) + sum([self.likelihood[word][\"ai\"] for word in tokens])\n","    predicted_author = \"human\" if log_score_human >=  log_score_ai else \"ai\"\n","    return predicted_author, {'human': log_score_human, 'ai': log_score_ai}\n","\n","  def score_test(self, test_df):\n","    true_positive = 0\n","    true_negative = 0\n","    false_positive = 0\n","    false_negative = 0\n","\n","    for index,review in test_df.iterrows():\n","      true_label = review['label']\n","      text = review['essay']\n","      predicted_author, sentiment_scores = self.classify_essay(text)\n","      if true_label == \"human\" and predicted_author == \"human\":\n","        true_negative =  true_negative + 1\n","      elif true_label == \"ai\" and predicted_author == \"ai\":\n","        true_positive = true_positive + 1\n","      elif true_label == \"human\" and predicted_author == \"ai\":\n","        false_negative = false_negative + 1\n","      elif true_label == \"ai\" and predicted_author == \"human\":\n","        false_positive = false_positive + 1\n","\n","    precision = true_positive / (true_positive + false_positive)\n","    recall = true_positive / (true_positive + false_negative)\n","    f1_score = (2 * precision * recall) / (precision + recall)\n","    return {\n","        \"true_negative\": true_negative,\n","        \"false_negative\": false_negative,\n","        \"true_positive\": true_positive,\n","        \"false_positive\": false_positive,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1_score\": f1_score\n","      }\n","\n","def evaluate_bayes(opts):\n","  df, test_df, dev_df = load_dfs(opts[\"language\"])\n","  bayes_model = AIDetector()\n","  bayes_model.train(df)\n","  return bayes_model.score_test(test_df)"]},{"cell_type":"markdown","metadata":{"id":"I5WCCiuhawVe"},"source":["#### Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"onmnHI7kkxiu","executionInfo":{"status":"ok","timestamp":1732843609021,"user_tz":300,"elapsed":6,"user":{"displayName":"Owen Van Esbroeck","userId":"13137652672025469070"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"40a76bc3-a65d-46a8-f298-322d84cd2bd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'human': 0, 'ai': 1}\n"]}],"source":["# !pip install transformers==3.5\n","# labels\n","label2idx = {'human': 0, 'ai': 1}\n","print(label2idx)\n","#\n","model_path = \"drive/MyDrive/GenAIContentDetection/model.pth\"\n","model_saved = False #os.path.exists(model_path)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":[],"metadata":{"id":"A-oyhS4X-HTw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dRQDpzd6nZDa"},"outputs":[],"source":["#logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n","#                    datefmt = '%m/%d/%Y %H:%M:%S',\n","#                    level = logging.INFO)\n","#logger = logging.getLogger(__name__)\n","\n","MAX_SEQ_LENGTH=100\n","\n","class BertInputItem(object):\n","    \"\"\"An item with all the necessary attributes for finetuning BERT.\"\"\"\n","\n","    def __init__(self, text, input_ids, input_mask, segment_ids, label_id):\n","        self.text = text\n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.segment_ids = segment_ids\n","        self.label_id = label_id\n","\n","def convert_examples_to_inputs(example_texts, example_labels, label2idx, max_seq_length, tokenizer, verbose=0):\n","      \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n","      input_items = []\n","      examples = zip(example_texts, example_labels)\n","      for (ex_index, (text, label)) in enumerate(examples):\n","          # Create a list of token ids\n","          input_ids = tokenizer.encode(f\"[CLS] {text} [SEP]\")\n","          if len(input_ids) > max_seq_length:\n","              input_ids = input_ids[:max_seq_length]\n","          # All our tokens are in the first input segment (id 0).\n","          segment_ids = [0] * len(input_ids)\n","          # The mask has 1 for real tokens and 0 for padding tokens. Only real\n","          # tokens are attended to.\n","          input_mask = [1] * len(input_ids)\n","          # Zero-pad up to the sequence length.\n","          padding = [0] * (max_seq_length - len(input_ids))\n","          input_ids += padding\n","          input_mask += padding\n","          segment_ids += padding\n","          assert len(input_ids) == max_seq_length\n","          assert len(input_mask) == max_seq_length\n","          assert len(segment_ids) == max_seq_length\n","          label_id = label2idx[label]\n","          input_items.append(\n","              BertInputItem(text=text,\n","                            input_ids=input_ids,\n","                            input_mask=input_mask,\n","                            segment_ids=segment_ids,\n","                            label_id=label_id))\n","      return input_items\n","\n","def get_features(opts, tokenizer):\n","  df, test_df, dev_df = load_dfs(opts[\"language\"])\n","  features= convert_examples_to_inputs(df['essay'].tolist(), df['label'], label2idx, MAX_SEQ_LENGTH, tokenizer, verbose=0)\n","  dev_features= convert_examples_to_inputs(dev_df['essay'].tolist(), dev_df['label'], label2idx, MAX_SEQ_LENGTH, tokenizer, verbose=0)\n","  test_features= convert_examples_to_inputs(test_df['essay'].tolist(), test_df['label'], label2idx, MAX_SEQ_LENGTH, tokenizer, verbose=0)\n","  return features, dev_features, test_features\n","\n","def get_features_from_file(path, tokenizer):\n","    df = create_dataframe_from_file(path)\n","    features = convert_examples_to_inputs(df['essay'].tolist(), df['label'], label2idx, MAX_SEQ_LENGTH, tokenizer, verbose=0)\n","    return features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtWXFjjTrqrz"},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n","\n","def get_data_loader(features, max_seq_length, batch_size, shuffle=True, max_length=1000):\n","\n","    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n","    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n","    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n","    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n","    data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n","\n","    dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size)\n","    return dataloader\n","\n","def get_data_loader_from_file(path, tokenizer, max_seq_length, batch_size, shuffle=True):\n","   features = get_features_from_file(path, tokenizer)\n","   dataloader = get_data_loader(features, max_seq_length, batch_size, shuffle=True)\n","   return dataloader\n","\n","def get_data_loaders(opts, tokenizer):\n","  features, dev_features, test_features = get_features(opts, tokenizer)\n","  train_dataloader = get_data_loader(features, MAX_SEQ_LENGTH, opts[\"batch_size\"], shuffle=True)\n","  test_dataloader = get_data_loader(test_features, MAX_SEQ_LENGTH, opts[\"batch_size\"], shuffle=True)\n","  dev_dataloader = get_data_loader(dev_features, MAX_SEQ_LENGTH, opts[\"batch_size\"], shuffle=True)\n","  return train_dataloader, test_dataloader, dev_dataloader\n"]},{"cell_type":"markdown","metadata":{"id":"zKrm3LQNaKuH"},"source":["#### Bert"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jxW8FZKraJzs"},"outputs":[],"source":["def evaluate_bert(model, dataloader):\n","    model.eval()\n","    predicted_labels, correct_labels = [], []\n","\n","    for step, batch in enumerate(tqdm(dataloader, desc=\"Evaluation iteration\")):\n","        batch = tuple(t.to(device) for t in batch)\n","        input_ids, input_mask, segment_ids, label_ids = batch\n","        with torch.no_grad():\n","            outputs = model(input_ids, attention_mask=input_mask,\n","                                          token_type_ids=segment_ids, labels=label_ids)\n","        output_labels = np.argmax(outputs.logits.to('cpu'), axis=1)\n","        label_ids = label_ids.to('cpu').numpy()\n","        predicted_labels += list(output_labels)\n","        correct_labels += list(label_ids)\n","\n","    correct_labels = np.array(correct_labels)\n","    predicted_labels = np.array(predicted_labels)\n","    true_positive = np.sum(np.logical_and(predicted_labels == 1, correct_labels == 1))\n","    true_negative = np.sum(np.logical_and(predicted_labels == 0, correct_labels == 0))\n","    false_positive = np.sum(np.logical_and(predicted_labels == 1, correct_labels == 0))\n","    false_negative = np.sum(np.logical_and(predicted_labels == 0, correct_labels == 1))\n","    precision = true_positive / (true_positive + false_positive)\n","    recall = true_positive / (true_positive + false_negative)\n","    f1_score = (2 * precision * recall) / (precision + recall)\n","    return {\n","        \"true_positive\": true_positive,\n","        \"true_negative\": true_negative,\n","        \"false_positive\": false_positive,\n","        \"false_negative\": false_negative,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1_score\": f1_score\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BDUq6DqsAytX"},"outputs":[],"source":["from tqdm import trange\n","from tqdm.notebook import tqdm\n","from sklearn.metrics import classification_report, precision_recall_fscore_support\n","\n","\n","def train_bert(opts, train_dataloader):\n","  bert_model = BertForSequenceClassification.from_pretrained(datasets[opts[\"language\"]][\"bert_model\"], num_labels = len(label2idx))\n","  bert_model.to(device)\n","  #\n","  LEARNING_RATE = 5e-5\n","  MAX_GRAD_NORM = 1\n","  #\n","  param_optimizer = list(bert_model.named_parameters())\n","  no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","  optimizer = torch.optim.AdamW(bert_model.parameters(), lr=LEARNING_RATE)\n","\n","  loss_history = []\n","  no_improvement = 0\n","  for _ in trange(int(opts[\"epochs\"]), desc=\"Epoch\"):\n","      bert_model.train()\n","      tr_loss = 0\n","      nb_tr_examples, nb_tr_steps = 0, 0\n","      for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training iteration\")):\n","          batch = tuple(t.to(device) for t in batch)\n","          input_ids, input_mask, segment_ids, label_ids = batch\n","\n","          outputs = bert_model(input_ids, attention_mask=input_mask, token_type_ids=segment_ids, labels=label_ids)\n","          loss = outputs[0]\n","          loss.backward()\n","          tr_loss += loss.item()\n","\n","          torch.nn.utils.clip_grad_norm_(bert_model.parameters(), MAX_GRAD_NORM)\n","\n","          optimizer.step()\n","          optimizer.zero_grad()\n","              #scheduler.step()\n","\n","      print(tr_loss)\n","  torch.save(bert_model.state_dict(), BASE_DIR + \"model_ffnn_\" + opts[\"language\"] +  \".bin\")\n","  return bert_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BsjM-tkMNCri"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"eA22Pb5SbMNL"},"source":["#### CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eIZbyhAAJ4r4"},"outputs":[],"source":["class BertCNNClassification(BertPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","        self.config = config\n","\n","        self.bert = BertModel(config)\n","        self.cnn = torch.nn.Conv1d(768, 10, 3, )\n","        self.pool = torch.nn.MaxPool1d(3)\n","        self.dropout = torch.nn.Dropout(0.2)\n","        self.fc = torch.nn.Linear(320, self.num_labels)\n","\n","        self.sigmoid = torch.nn.Sigmoid()\n","\n","\n","        # Initialize weights and apply final processing\n","        self.post_init()\n","\n","    def forward(\n","        self,\n","        input_ids = None,\n","        attention_mask = None,\n","        token_type_ids = None,\n","        labels = None,\n","\n","    ):\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            output_hidden_states=True\n","        )\n","\n","        #pooled_output = outputs[1]\n","        #pooled_output = self.dropout(pooled_output)\n","        x = outputs.last_hidden_state\n","        #print(x.shape)\n","        x = x.permute(0, 2, 1)\n","        #print(x.shape)\n","        x = self.cnn(x)\n","        x = self.pool(x)\n","        #print(pooled.shape)\n","        #print(x.shape)\n","        x = torch.flatten(x, start_dim=1)\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        x = self.sigmoid(x)\n","\n","\n","        loss = None\n","        if labels is not None:\n","          loss_fct = torch.nn.CrossEntropyLoss(reduction='mean')\n","          loss = loss_fct(x, labels)\n","          #print(x)\n","          #print(np.argmax(x.to('cpu').detach(), axis=1))\n","\n","        return [loss, x]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yWFbsCX1bV6q"},"outputs":[],"source":["def evaluate_cnn(model, dataloader):\n","    model.eval()\n","    predicted_labels, correct_labels = [], []\n","\n","    for step, batch in enumerate(tqdm(dataloader, desc=\"Evaluation iteration\")):\n","        batch = tuple(t.to(device) for t in batch)\n","        input_ids, input_mask, segment_ids, label_ids = batch\n","        with torch.no_grad():\n","            outputs = model(input_ids, attention_mask=input_mask,\n","                                          token_type_ids=segment_ids, labels=label_ids)\n","        print(outputs)\n","        output_labels = np.argmax(outputs[1].to('cpu'), axis=1)\n","        label_ids = label_ids.to('cpu').numpy()\n","        predicted_labels += list(output_labels)\n","        correct_labels += list(label_ids)\n","\n","    correct_labels = np.array(correct_labels)\n","    predicted_labels = np.array(predicted_labels)\n","    true_positive = np.sum(np.logical_and(predicted_labels == 1, correct_labels == 1))\n","    true_negative = np.sum(np.logical_and(predicted_labels == 0, correct_labels == 0))\n","    false_positive = np.sum(np.logical_and(predicted_labels == 1, correct_labels == 0))\n","    false_negative = np.sum(np.logical_and(predicted_labels == 0, correct_labels == 1))\n","    precision = true_positive / (true_positive + false_positive)\n","    recall = true_positive / (true_positive + false_negative)\n","    f1_score = (2 * precision * recall) / (precision + recall)\n","    return {\n","        \"true_positive\": true_positive,\n","        \"true_negative\": true_negative,\n","        \"false_positive\": false_positive,\n","        \"false_negative\": false_negative,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1_score\": f1_score\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftr3ZP0i0K-n"},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PfeRjFfvCqR4"},"outputs":[],"source":["def train_cnn(opts, train_dataloader):\n","  cnn_model = BertCNNClassification.from_pretrained(datasets[opts[\"language\"]][\"bert_model\"], num_labels = len(label2idx))\n","  torch.nn.init.uniform_(cnn_model.cnn.weight, -1, 1)\n","  torch.nn.init.uniform_(cnn_model.cnn.bias, -1, 1)\n","  torch.nn.init.uniform_(cnn_model.fc.weight, -1, 1)\n","  torch.nn.init.uniform_(cnn_model.fc.bias, -1, 1)\n","  cnn_model.to(device)\n","  #\n","  LEARNING_RATE = 5e-8\n","  WARMUP_PROPORTION = 0.1\n","  MAX_GRAD_NORM = 1\n","  #\n","  optimizer = torch.optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE)\n","\n","  loss_history = []\n","  no_improvement = 0\n","  for _ in trange(int(opts[\"epochs\"]),bert_model desc=\"Epoch\"):\n","    cnn_model.train()\n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training iteration\")):\n","      batch = tuple(t.to(device) for t in batch)\n","      input_ids, input_mask, segment_ids, label_ids = batch\n","\n","      outputs = cnn_model(input_ids, attention_mask=input_mask, token_type_ids=segment_ids, labels=label_ids)\n","      loss = outputs[0]\n","      loss.backward()\n","      torch.nn.utils.clip_grad_norm_(cnn_model.parameters(), MAX_GRAD_NORM)\n","      tr_loss += loss.item()\n","\n","      optimizer.step()\n","      optimizer.zero_grad()\n","    print(tr_loss)\n","  torch.save(cnn_model.state_dict(), BASE_DIR + \"model_cnn_\" + opts[\"language\"] +  \".bin\")\n","  return cnn_model\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kB9RS43Bbo6M"},"source":["#### RNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AORx0sgGDwsq"},"outputs":[],"source":["class BertRNNClassification(BertPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.layers = 1\n","        self.embed_dim = 768\n","        self.hidden_size = 5\n","        self.num_labels = config.num_labels\n","        self.config = config\n","\n","        self.bert = BertModel(config)\n","        self.dropout = torch.nn.Dropout(0.2)\n","        self.rnn = torch.nn.LSTM(self.embed_dim, self.hidden_size, self.layers)\n","        self.fc = torch.nn.Linear(self.hidden_size, self.num_labels)\n","        self.sigmoid = torch.nn.Sigmoid()\n","\n","\n","        # Initialize weights and apply final processing\n","        self.post_init()\n","\n","    def forward(\n","        self,\n","        input_ids = None,\n","        attention_mask = None,\n","        token_type_ids = None,\n","        labels = None,\n","\n","    ):\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            output_hidden_states=True\n","        )\n","        x = outputs.last_hidden_state\n","        h0 = torch.zeros(self.layers, x.size(1), self.hidden_size).to(device)\n","        c0 = torch.zeros(self.layers, x.size(1), self.hidden_size).to(device)\n","        x = self.dropout(x)\n","        x = self.rnn(x, (h0, c0))[0]\n","        x = self.fc(x[:, -1, :])\n","        x = self.sigmoid(x)\n","        loss = None\n","        if labels is not None:\n","          loss_fct = torch.nn.CrossEntropyLoss(reduction='mean')\n","          loss = loss_fct(x, labels)\n","\n","        return [loss, x]\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bOk7tDn1kui4"},"outputs":[],"source":["def train_rnn(opts, train_dataloader):\n","  rnn_model = BertRNNClassification.from_pretrained(datasets[opts[\"language\"]][\"bert_model\"], num_labels = len(label2idx))\n","  rnn_model.to(device)\n","  GRADIENT_ACCUMULATION_STEPS = 1\n","  LEARNING_RATE = 5e-8\n","  MAX_GRAD_NORM = 1\n","  #\n","  optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=LEARNING_RATE)\n","\n","  loss_history = []\n","  no_improvement = 0\n","  for _ in trange(int(opts[\"epochs\"]), desc=\"Epoch\"):\n","    rnn_model.train()\n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training iteration\")):\n","      batch = tuple(t.to(device) for t in batch)\n","      input_ids, input_mask, segment_ids, label_ids = batch\n","\n","      outputs = rnn_model(input_ids, attention_mask=input_mask, token_type_ids=segment_ids, labels=label_ids)\n","      loss = outputs[0]\n","\n","      loss.backward()\n","      torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), MAX_GRAD_NORM)\n","      tr_loss += loss.item()\n","\n","\n","      optimizer.step()\n","      optimizer.zero_grad()\n","    print(tr_loss)\n","  torch.save(rnn_model.state_dict(), BASE_DIR + \"model_rnn_\" + opts[\"language\"] +  \".bin\")\n","  return rnn_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A0hL8B3rlSk1"},"outputs":[],"source":["def evaluate_rnn(model, dataloader):\n","    model.eval()\n","    predicted_labels, correct_labels = [], []\n","\n","    for step, batch in enumerate(tqdm(dataloader, desc=\"Evaluation iteration\")):\n","        batch = tuple(t.to(device) for t in batch)\n","        input_ids, input_mask, segment_ids, label_ids = batch\n","        with torch.no_grad():\n","            outputs = model(input_ids, attention_mask=input_mask,\n","                                          token_type_ids=segment_ids, labels=label_ids)\n","        output_labels = np.argmax(outputs[1].to('cpu'), axis=1)\n","        label_ids = label_ids.to('cpu').numpy()\n","        predicted_labels += list(output_labels)\n","        correct_labels += list(label_ids)\n","\n","    correct_labels = np.array(correct_labels)\n","    predicted_labels = np.array(predicted_labels)\n","    true_positive = np.sum(np.logical_and(predicted_labels == 1, correct_labels == 1))\n","    true_negative = np.sum(np.logical_and(predicted_labels == 0, correct_labels == 0))\n","    false_positive = np.sum(np.logical_and(predicted_labels == 1, correct_labels == 0))\n","    false_negative = np.sum(np.logical_and(predicted_labels == 0, correct_labels == 1))\n","    precision = true_positive / (true_positive + false_positive)\n","    recall = true_positive / (true_positive + false_negative)\n","    f1_score = (2 * precision * recall) / (precision + recall)\n","    return {\n","        \"true_positive\": true_positive,\n","        \"true_negative\": true_negative,\n","        \"false_positive\": false_positive,\n","        \"false_negative\": false_negative,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1_score\": f1_score\n","    }\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"cKLxmVSy9gsL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"x8hPvY_3lWVQ"},"outputs":[],"source":[]},{"cell_type":"code","source":["opts = {\n","    \"language\": \"english\",\n","    \"batch_size\": 16,\n","    \"epochs\": 15,\n","    \"model\": \"rnn\"\n","}\n","tokenizer = BertTokenizer.from_pretrained(datasets[opts[\"language\"]][\"bert_model\"])\n","model = opts[\"model\"]\n","\n","train_dataloader, test_dataloader, dev_dataloader = get_data_loaders(opts, tokenizer)\n","scores = None\n","if model == \"bayes\":\n","  scores = evaluate_bayes(opts)\n","elif model == \"bert\":\n","  bert_model = train_bert(opts, train_dataloader)\n","  scores = evaluate_bert(bert_model, dev_dataloader)\n","elif model == \"cnn\":\n","  cnn_model = train_cnn(opts, train_dataloader)\n","  scores = evaluate_cnn(cnn_model, dev_dataloader)\n","elif model == \"rnn\":\n","  rnn_model = train_rnn(opts, train_dataloader)\n","  scores = evaluate_rnn(rnn_model, dev_dataloader)\n","print(scores)"],"metadata":{"id":"cGHi1m5nnTJh","colab":{"base_uri":"https://localhost:8080/","height":440,"referenced_widgets":["71f3852db5b9424c916a3a905c6dc901","86d10d2d41c14b22a1607a978abbbae3","f3b17360c7d0464491de2fdefadf02eb","cc02dd9c88f44cacb31437437acc120d","a801b7d5adc94482a90e374b0364fc05","e64f7e0fc7a34e819aa777208bbf2f10","ffef1b204d2440b4a0ecaea01c80be86","448eb6e5a89141bb9346d148496cc3fd","2d0e109fefb04a36b1d7848542d70bfb","3c9ab3b2382242de9858d20a52db86f0","2331bd096f804f9b9e054a7788f3a478","59dc2a8f4a554a80bfa798204a09ceda","c4391cb215e74d1e9778ebbd6ae9dad3","5717764dd8364538bfa2843a8b3e9079","dee3e604efec46f0abb0dffbfdfa0eb1","cb4979f88e0a43589df8819191398979","433f6f6ac3b94616a437137236c550dd","c7c836db67cf421d98251676fccc1ac2","d3b061a2cc11414bbc43d038780c4cb5","11c9284a51b64070bbbbcc58dc65e132","16336c91f56349019411ac14451176e1","58f78a0db62d4ba5ab804f7a78701a82","364421be6b3941a18d7d669c89987dee","849a252628e64511afcb6be9d381b00b","59b1b0afbd3846a6b59e46789dd2e6f7","5f3bf1cd978e4cfcbc6d38f459510b70","942520a0092948f3956d31ec3b2cc877","4207708e0ee54278a51892f02d539bf1","04e6e70fed644100b62856a213a9f6a7","e11dee2915d94a7c8beab080c8effbca","92d7111e8b7f48639a61ede344884462","9ae2a0a67e6b400eba31b968a8f44ded","a4b27787c7c24e90beb0415f9db145ca","09457c229a5c47a0af2cd1936b7ac65b","6038ddd634594d9b9959db36a8ac6b6a","9b2877ac82ec4a6381fda043c4b0ebae","6fffadfea49c431fa0c09158949e827a","bc747e32abd24a838fee2670a572f4a7","bc39cc4f81e24ac2b258ec6d51c479fa","e8bcccd3c63a4302b113d44a8bf7df2d","f382d7f55c2640f0bae1097c1a78f712","fc9b8ab69a4d4458891063db6bf6d1df","b7543eaec7554fd99db50afadb95af46","d6d8510008924d69b662579ec7a2fb72","613c78b77bd645cd88daf450f8315612","782d007cde4742e8b61fafa465831a74","29c6e655ce4142adb27c0953949eefd6","0e0689a7176a4061829609379937153c","a3eebc9d0f884926af783336641f2cef","e927600a9b40412f912f1751ab7c8586","662b6caa956e4c97bf0fa2d38875a850","d4f59125544e4edbb1e4f01d8a65be8c","263a5821096c4d83a38a2bb0532f7e86","b4da9b20fca744a8b13f0cc49e4f52b3","9b2588e6d33a4aa3a3a72525b8a099d2"]},"outputId":"002ab34d-33e9-4355-f405-ee1e881eb05f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n","Some weights of BertRNNClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['fc.bias', 'fc.weight', 'rnn.bias_hh_l0', 'rnn.bias_ih_l0', 'rnn.weight_hh_l0', 'rnn.weight_ih_l0']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch:   0%|          | 0/15 [00:00<?, ?it/s]"]},{"output_type":"display_data","data":{"text/plain":["Training iteration:   0%|          | 0/131 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71f3852db5b9424c916a3a905c6dc901"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\rEpoch:   7%|▋         | 1/15 [00:31<07:19, 31.36s/it]"]},{"output_type":"stream","name":"stdout","text":["nan\n"]},{"output_type":"display_data","data":{"text/plain":["Training iteration:   0%|          | 0/131 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59dc2a8f4a554a80bfa798204a09ceda"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\rEpoch:  13%|█▎        | 2/15 [01:01<06:40, 30.83s/it]"]},{"output_type":"stream","name":"stdout","text":["nan\n"]},{"output_type":"display_data","data":{"text/plain":["Training iteration:   0%|          | 0/131 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"364421be6b3941a18d7d669c89987dee"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\rEpoch:  20%|██        | 3/15 [01:32<06:10, 30.92s/it]"]},{"output_type":"stream","name":"stdout","text":["nan\n"]},{"output_type":"display_data","data":{"text/plain":["Training iteration:   0%|          | 0/131 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09457c229a5c47a0af2cd1936b7ac65b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\rEpoch:  27%|██▋       | 4/15 [02:05<05:46, 31.53s/it]"]},{"output_type":"stream","name":"stdout","text":["nan\n"]},{"output_type":"display_data","data":{"text/plain":["Training iteration:   0%|          | 0/131 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"613c78b77bd645cd88daf450f8315612"}},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"DQN6IMIjaV15"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"71f3852db5b9424c916a3a905c6dc901":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86d10d2d41c14b22a1607a978abbbae3","IPY_MODEL_f3b17360c7d0464491de2fdefadf02eb","IPY_MODEL_cc02dd9c88f44cacb31437437acc120d"],"layout":"IPY_MODEL_a801b7d5adc94482a90e374b0364fc05"}},"86d10d2d41c14b22a1607a978abbbae3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e64f7e0fc7a34e819aa777208bbf2f10","placeholder":"​","style":"IPY_MODEL_ffef1b204d2440b4a0ecaea01c80be86","value":"Training iteration: 100%"}},"f3b17360c7d0464491de2fdefadf02eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_448eb6e5a89141bb9346d148496cc3fd","max":131,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2d0e109fefb04a36b1d7848542d70bfb","value":131}},"cc02dd9c88f44cacb31437437acc120d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c9ab3b2382242de9858d20a52db86f0","placeholder":"​","style":"IPY_MODEL_2331bd096f804f9b9e054a7788f3a478","value":" 131/131 [00:31&lt;00:00,  4.29it/s]"}},"a801b7d5adc94482a90e374b0364fc05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e64f7e0fc7a34e819aa777208bbf2f10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffef1b204d2440b4a0ecaea01c80be86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"448eb6e5a89141bb9346d148496cc3fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d0e109fefb04a36b1d7848542d70bfb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c9ab3b2382242de9858d20a52db86f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2331bd096f804f9b9e054a7788f3a478":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59dc2a8f4a554a80bfa798204a09ceda":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c4391cb215e74d1e9778ebbd6ae9dad3","IPY_MODEL_5717764dd8364538bfa2843a8b3e9079","IPY_MODEL_dee3e604efec46f0abb0dffbfdfa0eb1"],"layout":"IPY_MODEL_cb4979f88e0a43589df8819191398979"}},"c4391cb215e74d1e9778ebbd6ae9dad3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_433f6f6ac3b94616a437137236c550dd","placeholder":"​","style":"IPY_MODEL_c7c836db67cf421d98251676fccc1ac2","value":"Training iteration: 100%"}},"5717764dd8364538bfa2843a8b3e9079":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3b061a2cc11414bbc43d038780c4cb5","max":131,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11c9284a51b64070bbbbcc58dc65e132","value":131}},"dee3e604efec46f0abb0dffbfdfa0eb1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16336c91f56349019411ac14451176e1","placeholder":"​","style":"IPY_MODEL_58f78a0db62d4ba5ab804f7a78701a82","value":" 131/131 [00:30&lt;00:00,  4.30it/s]"}},"cb4979f88e0a43589df8819191398979":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"433f6f6ac3b94616a437137236c550dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7c836db67cf421d98251676fccc1ac2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3b061a2cc11414bbc43d038780c4cb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11c9284a51b64070bbbbcc58dc65e132":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16336c91f56349019411ac14451176e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58f78a0db62d4ba5ab804f7a78701a82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"364421be6b3941a18d7d669c89987dee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_849a252628e64511afcb6be9d381b00b","IPY_MODEL_59b1b0afbd3846a6b59e46789dd2e6f7","IPY_MODEL_5f3bf1cd978e4cfcbc6d38f459510b70"],"layout":"IPY_MODEL_942520a0092948f3956d31ec3b2cc877"}},"849a252628e64511afcb6be9d381b00b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4207708e0ee54278a51892f02d539bf1","placeholder":"​","style":"IPY_MODEL_04e6e70fed644100b62856a213a9f6a7","value":"Training iteration: 100%"}},"59b1b0afbd3846a6b59e46789dd2e6f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e11dee2915d94a7c8beab080c8effbca","max":131,"min":0,"orientation":"horizontal","style":"IPY_MODEL_92d7111e8b7f48639a61ede344884462","value":131}},"5f3bf1cd978e4cfcbc6d38f459510b70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ae2a0a67e6b400eba31b968a8f44ded","placeholder":"​","style":"IPY_MODEL_a4b27787c7c24e90beb0415f9db145ca","value":" 131/131 [00:31&lt;00:00,  4.11it/s]"}},"942520a0092948f3956d31ec3b2cc877":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4207708e0ee54278a51892f02d539bf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04e6e70fed644100b62856a213a9f6a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e11dee2915d94a7c8beab080c8effbca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92d7111e8b7f48639a61ede344884462":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ae2a0a67e6b400eba31b968a8f44ded":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4b27787c7c24e90beb0415f9db145ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09457c229a5c47a0af2cd1936b7ac65b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6038ddd634594d9b9959db36a8ac6b6a","IPY_MODEL_9b2877ac82ec4a6381fda043c4b0ebae","IPY_MODEL_6fffadfea49c431fa0c09158949e827a"],"layout":"IPY_MODEL_bc747e32abd24a838fee2670a572f4a7"}},"6038ddd634594d9b9959db36a8ac6b6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc39cc4f81e24ac2b258ec6d51c479fa","placeholder":"​","style":"IPY_MODEL_e8bcccd3c63a4302b113d44a8bf7df2d","value":"Training iteration: 100%"}},"9b2877ac82ec4a6381fda043c4b0ebae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f382d7f55c2640f0bae1097c1a78f712","max":131,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fc9b8ab69a4d4458891063db6bf6d1df","value":131}},"6fffadfea49c431fa0c09158949e827a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7543eaec7554fd99db50afadb95af46","placeholder":"​","style":"IPY_MODEL_d6d8510008924d69b662579ec7a2fb72","value":" 131/131 [00:32&lt;00:00,  4.14it/s]"}},"bc747e32abd24a838fee2670a572f4a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc39cc4f81e24ac2b258ec6d51c479fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8bcccd3c63a4302b113d44a8bf7df2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f382d7f55c2640f0bae1097c1a78f712":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc9b8ab69a4d4458891063db6bf6d1df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7543eaec7554fd99db50afadb95af46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6d8510008924d69b662579ec7a2fb72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"613c78b77bd645cd88daf450f8315612":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_782d007cde4742e8b61fafa465831a74","IPY_MODEL_29c6e655ce4142adb27c0953949eefd6","IPY_MODEL_0e0689a7176a4061829609379937153c"],"layout":"IPY_MODEL_a3eebc9d0f884926af783336641f2cef"}},"782d007cde4742e8b61fafa465831a74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e927600a9b40412f912f1751ab7c8586","placeholder":"​","style":"IPY_MODEL_662b6caa956e4c97bf0fa2d38875a850","value":"Training iteration:  44%"}},"29c6e655ce4142adb27c0953949eefd6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4f59125544e4edbb1e4f01d8a65be8c","max":131,"min":0,"orientation":"horizontal","style":"IPY_MODEL_263a5821096c4d83a38a2bb0532f7e86","value":58}},"0e0689a7176a4061829609379937153c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4da9b20fca744a8b13f0cc49e4f52b3","placeholder":"​","style":"IPY_MODEL_9b2588e6d33a4aa3a3a72525b8a099d2","value":" 58/131 [00:13&lt;00:17,  4.14it/s]"}},"a3eebc9d0f884926af783336641f2cef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e927600a9b40412f912f1751ab7c8586":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"662b6caa956e4c97bf0fa2d38875a850":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4f59125544e4edbb1e4f01d8a65be8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"263a5821096c4d83a38a2bb0532f7e86":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4da9b20fca744a8b13f0cc49e4f52b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b2588e6d33a4aa3a3a72525b8a099d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
